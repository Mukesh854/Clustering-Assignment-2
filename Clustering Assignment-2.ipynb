{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38303a0d-87f6-4a67-9ebc-16742c294a1a",
   "metadata": {},
   "source": [
    "# Clustering Assignment-2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f64688a-c338-4b9b-b0ad-bfa55d43f0b5",
   "metadata": {},
   "source": [
    "Q1. What is hierarchical clustering, and how is it different from other clustering techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab32d4c4-0316-4006-b46c-f16f90d6126e",
   "metadata": {},
   "source": [
    "\n",
    "Hierarchical clustering groups similar data points into clusters by creating a tree-like structure of clusters, while other clustering techniques like k-means require specifying the number of clusters beforehand and assume spherical clusters. Hierarchical clustering is more flexible, accommodating different cluster shapes and sizes, and it provides a hierarchical view of the data's clustering patterns. However, it can be computationally intensive compared to some other methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8979871-13e8-4ec9-84a2-0115c74a4b7e",
   "metadata": {},
   "source": [
    "Q2. What are the two main types of hierarchical clustering algorithms? Describe each in brief."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8e2366-08dd-443d-84a6-16226ccff792",
   "metadata": {},
   "source": [
    "\n",
    "The two main types of hierarchical clustering algorithms are:\n",
    "\n",
    "1) Agglomerative Hierarchical Clustering:\n",
    "\n",
    "2) Divisive Hierarchical Clustering:\n",
    "\n",
    ". Agglomerative clustering starts with individual data points as clusters and merges them until all points belong to one cluster, forming a dendrogram. \n",
    "\n",
    ". Divisive clustering begins with all points in one cluster and divides them recursively until each point is its own cluster, also producing a dendrogram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2be499-1a10-44d1-9ac0-ffb1010df76a",
   "metadata": {},
   "source": [
    "Q3. How do you determine the distance between two clusters in hierarchical clustering, and what are the\n",
    "common distance metrics used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa20b53-bde8-4fa3-b327-0b7947bf0a46",
   "metadata": {},
   "source": [
    "\n",
    "The distance between two clusters in hierarchical clustering is determined using a distance metric. Common metrics include Euclidean distance for numerical data, Manhattan distance for categorical data, cosine similarity for text data, correlation distance for pattern similarity, Mahalanobis distance for correlated features, and Jaccard distance for binary or categorical data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcf1305-e33f-4478-880e-9b066ae23eed",
   "metadata": {},
   "source": [
    "Q4. How do you determine the optimal number of clusters in hierarchical clustering, and what are some\n",
    "common methods used for this purpose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0d9c80-ae0a-47a7-b2d7-bf4b98da451b",
   "metadata": {},
   "source": [
    "Dendrogram Visualization: Examining the dendrogram for natural breakpoints.\n",
    "\n",
    "Cutting the Dendrogram: Selecting a height to cut the dendrogram.\n",
    "\n",
    "Interpreting Cluster Sizes: Analyzing sizes of clusters.\n",
    "\n",
    "Gap Statistics: Comparing within-cluster dispersion to a reference distribution.\n",
    "\n",
    "Silhouette Score: Calculating the average silhouette coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b50f330-062a-472f-8f17-82199cd75b16",
   "metadata": {},
   "source": [
    "Q5. What are dendrograms in hierarchical clustering, and how are they useful in analyzing the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c533e3-f8b9-4c6b-84ea-2b5c764a5dad",
   "metadata": {},
   "source": [
    "\n",
    "Dendrograms are visual representations of hierarchical clustering results, showing the merging and splitting of clusters. They help in understanding cluster relationships, determining the optimal number of clusters, interpreting cluster similarity, understanding cluster composition, and comparing different clustering outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30db1169-d911-499d-9803-4ab424ac75f9",
   "metadata": {},
   "source": [
    "Q6. Can hierarchical clustering be used for both numerical and categorical data? If yes, how are the\n",
    "distance metrics different for each type of data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74515a90-49e6-4ae6-9703-3b3f85419a9a",
   "metadata": {},
   "source": [
    "Hierarchical clustering can be applied to both numerical and categorical data. For numerical data, metrics like Euclidean or Manhattan distance are used, while for categorical data, metrics like Jaccard or Hamming distance are employed. If data is mixed, specialized metrics like Gower distance can be utilized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff4206b-194e-42e4-9594-762c0a318acc",
   "metadata": {},
   "source": [
    "Q7. How can you use hierarchical clustering to identify outliers or anomalies in your data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f58e9fa-7f8b-422d-8adc-70201c77d355",
   "metadata": {},
   "source": [
    "we can use hierarchical clustering to identify outlier or anomalies in our data by this :-\n",
    "\n",
    ". Clustering similar data points.\n",
    "\n",
    ". Examining clusters with few points or those distant from others.\n",
    "\n",
    ". Calculating distances to cluster centroids.\n",
    "\n",
    ". Utilizing density-based approaches like DBSCAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae04920a-183e-4701-9dd6-5b789d0c8acc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
